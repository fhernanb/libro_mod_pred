# Regresión lineal versus árboles de regresión {#regarb}

## Regresión lineal
El modelo de regresión lineal simple es uno de los más populares en modelación. Este modelo se puede resumir a continuación.

\begin{align}
y_i &\sim N(\mu_i, \sigma^2), \\ 
\mu_i &= \beta_0 + \beta_1 x_i, \\
\sigma^2 &= \text{constante}
\end{align}

## Arboles de regresión
Un árbol de regresión es un árbol de decisión. Para conocer más sobre el tema se recomienda ver [este video](https://www.youtube.com/watch?v=7VeUPuFGJHk).

Las librerías en R para implementar árboles de regresión son:

```{r, message=FALSE}
library(rpart)
library(rpart.plot)
```

## Ejemplo 1
Como ilustración vamos a usar los datos del ejemplo 2.1 del libro de [Montgomery, Peck and Vining (2003)](https://www.amazon.com/Introduccion-analisis-regresion-lineal-Spanish/dp/9702403278). En el ejemplo 2.1 los autores ajustaron un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma. 

A continuación el código para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total tenemos 20 observaciones.

```{r}
file <- "https://raw.githubusercontent.com/fhernanb/datos/master/propelente"
datos <- read.table(file=file, header=TRUE)
head(datos) # shows the first 6 rows
```

Para crear un diagrama de dispersión que nos muestre la relación entre las dos variables usamos las siguientes instrucciones.

```{r soldadura1, fig.height=3, fig.width=5, fig.align='center', message=FALSE}
library(ggplot2)
ggplot(datos, aes(x=Edad, y=Resistencia)) + 
  geom_point() + theme_light()
```

De la figura anterior se ve claramente que a medida que aumenta la edad de la soldadura, la resistencia que ella ofrece disminuye. Adicionalmente, se observa que la relación entre las variables es lineal con una dispersión que parece constante.

¿Quién estima mejor? ¿un modelo de regresión lineal simple o un árbol?

```{r}
rls <- lm(Resistencia ~ Edad, data=datos)
arb <- rpart(Resistencia ~ Edad, data=datos)
```

```{r}
arb <- rpart(Resistencia ~ Edad, data=datos, method="anova")
prp(arb)
```


¿Qué hay dentro de modelo de regresión lineal simple?
```{r}
summary(rls)
```

¿Qué hay dentro de modelo del arbol?
```{r}
summary(arb)
```

Dijuemos el árbol con `prp`.
```{r}
prp(arb)
```

Construyamos nuevamente el árbol pero explorando todas las opciones de la función `prp`.
```{r  fig.width=8, fig.height=5}
prp(arb, main = "Mi árbol bonito",
    nn = TRUE,             # display the node numbers
    fallen.leaves = TRUE,  # put the leaves on the bottom of the page
    shadow.col = "gray",   # shadows under the leaves
    branch.lty = 3,        # draw branches using dotted lines
    branch = .5,           # change angle of branch lines
    faclen = 0,            # faclen = 0 to print full factor names
    trace = 1,             # print the auto calculated cex, xlim, ylim
    split.cex = 1.2,       # make the split text larger than the node text
    split.prefix = "is ",  # put "is " before split text
    split.suffix = "?",    # put "?" after split text
    split.box.col = "lightgray",   # lightgray split boxes (default is white)
    split.border.col = "darkgray", # darkgray border on split boxes
    split.round = .5)              # round the split box corners a tad
```


A continuación las predicciones con ambos modelos.

```{r}
pred_rls <- predict(object=rls, newdata=datos)
pred_arb <- predict(object=arb, newdata=datos)
```


Dibujemos $y_i$ versus $\hat{y}_i$.

```{r fig.width=8, fig.height=5}
par(mfrow=c(1, 2))
plot(x=pred_rls, y=datos$Resistencia, main="RLS")
abline(a=0, b=1, lty="dashed", col="blue")
plot(x=pred_arb, y=datos$Resistencia, main="Arbol")
abline(a=0, b=1, lty="dashed", col="blue")
```


Vamos a calcular $Cor(y_i, \hat{y}_i)$.

```{r}
cor(datos$Resistencia, pred_rls)
cor(datos$Resistencia, pred_arb)
```

Calculemos ahora el Error Cuadrático Medio $ECM=\frac{1}{n}\sum(y_i-\hat{y}_i)^2$.

```{r}
mean((datos$Resistencia - pred_rls)^2)
mean((datos$Resistencia - pred_arb)^2)
```

¿Cuál método prefiere usted?
