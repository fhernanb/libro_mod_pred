<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 AdaBoost | Modelos Predictivos</title>
  <meta name="description" content="Libro de Modelos Predictivos" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="6 AdaBoost | Modelos Predictivos" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Libro de Modelos Predictivos" />
  <meta name="github-repo" content="fhernanb/libro_mod_pred" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 AdaBoost | Modelos Predictivos" />
  
  <meta name="twitter:description" content="Libro de Modelos Predictivos" />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="Freddy Hernández" />


<meta name="date" content="2024-10-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="svm-clas.html"/>
<link rel="next" href="gradboost.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Predictivos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenido</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-libro"><i class="fa fa-check"></i>Estructura del libro</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-y-convenciones"><i class="fa fa-check"></i>Software y convenciones</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bloques-informativos"><i class="fa fa-check"></i>Bloques informativos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="arb-de-regre.html"><a href="arb-de-regre.html"><i class="fa fa-check"></i><b>1</b> Árboles de regresión</a>
<ul>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árboles"><i class="fa fa-check"></i>Árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árbol-de-decisión"><i class="fa fa-check"></i>Árbol de decisión</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#tipos-de-árboles"><i class="fa fa-check"></i>Tipos de árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árbol-de-regresión"><i class="fa fa-check"></i>Árbol de regresión</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#paquetes-de-r-para-árboles"><i class="fa fa-check"></i>Paquetes de R para árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#paquete-rpart"><i class="fa fa-check"></i>Paquete <strong>rpart</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#paquete-tree"><i class="fa fa-check"></i>Paquete <strong>tree</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#ejemplo-con-el-paquete-rpart"><i class="fa fa-check"></i>Ejemplo con el paquete <strong>rpart</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#ejemplo-con-el-paquete-tree"><i class="fa fa-check"></i>Ejemplo con el paquete <strong>tree</strong></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html"><i class="fa fa-check"></i><b>2</b> Árboles de clasificación</a>
<ul>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árboles-1"><i class="fa fa-check"></i>Árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árbol-de-decisión-1"><i class="fa fa-check"></i>Árbol de decisión</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#tipos-de-árboles-1"><i class="fa fa-check"></i>Tipos de árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árbol-de-clasificación"><i class="fa fa-check"></i>Árbol de clasificación</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#paquetes-de-r-para-construir-árboles"><i class="fa fa-check"></i>Paquetes de R para construir árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#ejemplo-con-rpart"><i class="fa fa-check"></i>Ejemplo con <strong>rpart</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#ejemplo-con-tree"><i class="fa fa-check"></i>Ejemplo con <strong>tree</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arb-distri.html"><a href="arb-distri.html"><i class="fa fa-check"></i><b>3</b> Árboles de regresión distribucionales</a>
<ul>
<li class="chapter" data-level="" data-path="arb-distri.html"><a href="arb-distri.html#videos-útiles"><i class="fa fa-check"></i>Videos útiles</a></li>
<li class="chapter" data-level="" data-path="arb-distri.html"><a href="arb-distri.html#paquete-disttree"><i class="fa fa-check"></i>Paquete disttree</a></li>
<li class="chapter" data-level="" data-path="arb-distri.html"><a href="arb-distri.html#ejemplo-1"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="arb-distri.html"><a href="arb-distri.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="svm-reg.html"><a href="svm-reg.html"><i class="fa fa-check"></i><b>4</b> Support Vector Machines para regresión</a>
<ul>
<li class="chapter" data-level="" data-path="svm-reg.html"><a href="svm-reg.html#paquetes-de-r-para-svm"><i class="fa fa-check"></i>Paquetes de R para svm</a></li>
<li class="chapter" data-level="" data-path="svm-reg.html"><a href="svm-reg.html#ventajas"><i class="fa fa-check"></i>Ventajas</a></li>
<li class="chapter" data-level="" data-path="svm-reg.html"><a href="svm-reg.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="svm-clas.html"><a href="svm-clas.html"><i class="fa fa-check"></i><b>5</b> Support Vector Machines para clasificación</a>
<ul>
<li class="chapter" data-level="" data-path="svm-clas.html"><a href="svm-clas.html#paquetes-de-r-para-svm-1"><i class="fa fa-check"></i>Paquetes de R para svm</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="adaboost.html"><a href="adaboost.html"><i class="fa fa-check"></i><b>6</b> AdaBoost</a>
<ul>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#explicación-sencilla-de-adaboost"><i class="fa fa-check"></i>Explicación sencilla de AdaBoost</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#explicación-detallada-de-adaboost"><i class="fa fa-check"></i>Explicación detallada de AdaBoost</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-3"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-4"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-5"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-6"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="gradboost.html"><a href="gradboost.html"><i class="fa fa-check"></i><b>7</b> Gradient Boost</a>
<ul>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-9"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="rand_forests.html"><a href="rand_forests.html"><i class="fa fa-check"></i><b>8</b> Random Forest</a>
<ul>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#explicación-sencilla-de-random-forests"><i class="fa fa-check"></i>Explicación sencilla de Random Forests</a></li>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#ejemplo-10"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#ejemplo-11"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#ejemplo-12"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#random-forests-distribucionales"><i class="fa fa-check"></i>Random Forests distribucionales</a></li>
<li class="chapter" data-level="" data-path="rand_forests.html"><a href="rand_forests.html#ejemplo-13"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html"><i class="fa fa-check"></i><b>9</b> Regresión lineal versus árboles de regresión</a>
<ul>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#regresión-lineal"><i class="fa fa-check"></i>Regresión lineal</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#arboles-de-regresión"><i class="fa fa-check"></i>Arboles de regresión</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#ejemplo-14"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#estudio-de-simulación-para-comparar-ambos-métodos"><i class="fa fa-check"></i>Estudio de simulación para comparar ambos métodos</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#retos"><i class="fa fa-check"></i>Retos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Predictivos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="adaboost" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> AdaBoost<a href="adaboost.html#adaboost" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>AdaBoost (adaptive boosting) fue propuesto por <span class="citation">Freund and Schapire (<a href="#ref-freund_1995">1995</a>)</span> y consiste en crear varios predictores sencillos en secuencia, de tal manera que el segundo ajuste bien lo que el primero no ajustó, que el tercero ajuste lo que el segundo no pudo ajustar y así sucesivamente. En la siguiente figura se muestra una ilustración de lo que es AdaBoost.</p>
<p align="center">
<img src="images/adaboost_illustration.png" width="700">
</p>
<div id="explicación-sencilla-de-adaboost" class="section level2 unnumbered hasAnchor">
<h2>Explicación sencilla de AdaBoost<a href="adaboost.html#explicación-sencilla-de-adaboost" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Entrene un clasificador.</li>
<li>Use el clasificador.</li>
<li>Identifique los casos que fueron mal clasificados.</li>
<li>Construya un nuevo clasificador que clasifique mejor los casos mal clasificados del punto anterior.</li>
<li>Repita los pasos 2 a 4 varias veces.</li>
<li>Asígnele un peso a cada clasificador y júntelos para obtener un clasificador con mejor desempeño.</li>
</ol>
</div>
<div id="explicación-detallada-de-adaboost" class="section level2 unnumbered hasAnchor">
<h2>Explicación detallada de AdaBoost<a href="adaboost.html#explicación-detallada-de-adaboost" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Inicie con un conjunto de entrenamiento <span class="math inline">\((X, Y)\)</span> con <span class="math inline">\(m\)</span> observaciones denotadas como <span class="math inline">\((x_1, y_1), \ldots, (x_m, y_m)\)</span> de tal manera que <span class="math inline">\(x_i \in R^p\)</span>. Los valores de <span class="math inline">\(y\)</span> deben ser -1 o 1 para aplicar el método.</li>
<li>Inicie con la distribución discreta <span class="math inline">\(D_1(i)=1/m\)</span> que indica el peso de la observación <span class="math inline">\(i\)</span> en la iteración <span class="math inline">\(1\)</span>.</li>
<li>Para <span class="math inline">\(t=1, \ldots, T\)</span>.</li>
</ol>
<ul>
<li>Construya un clasificador <span class="math inline">\(h_t\)</span> definido así: <span class="math inline">\(h_t : X \rightarrow \{-1, 1 \}\)</span>.</li>
<li>Calcule el error asociado <span class="math inline">\(\epsilon_t\)</span> al clasificador <span class="math inline">\(\epsilon_t= \sum_{i=1}^m D_t(i) \times \delta_i\)</span>, donde <span class="math inline">\(\delta_i=0\)</span> si <span class="math inline">\(h_t(x_i)=y_i\)</span>, es decir, si fue correcta la clasificación; caso contrario es <span class="math inline">\(\delta_i=1\)</span>.</li>
<li>Calcule la nueva distribución <span class="math inline">\(D_{t+1}(i)=D_{t}(i) \times F_i / Z_t\)</span>, donde:
<ul>
<li><span class="math inline">\(F_i=\exp(-\alpha_t)\)</span> si la clasificación fue correcta, es decir si <span class="math inline">\(h_t(x_i) = y_i\)</span>.</li>
<li><span class="math inline">\(F_i=\exp(\alpha_t)\)</span> si la clasificación fue incorrecta, es decir si <span class="math inline">\(h_t(x_i) \neq y_i\)</span>.</li>
<li><span class="math inline">\(\alpha_t=\frac{1}{2} \log \left( \frac{1-\epsilon_t}{\epsilon_t} \right)\)</span>.</li>
<li><span class="math inline">\(Z_t\)</span> es una constante de normalización de tal manera que <span class="math inline">\(\sum_{i=1}^m D_t(i)=1\)</span>. Usualmente es <span class="math inline">\(\sum D_{t}(i) \times F_i\)</span>.</li>
</ul></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Construya el clasificador final <span class="math inline">\(H_{final}\)</span> como el promedio ponderado de los <span class="math inline">\(t\)</span> clasificadores <span class="math inline">\(h_t\)</span>, usando <span class="math inline">\(H_{final}=sign(\sum_t \alpha_t h_t(x))\)</span>.</li>
</ol>
</div>
<div id="ejemplo-3" class="section level2 unnumbered hasAnchor">
<h2>Ejemplo<a href="adaboost.html#ejemplo-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Abajo se presenta un video con una explicación detallada de lo que es AdaBoost.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/LsK-xG1cLYA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="ejemplo-4" class="section level2 unnumbered hasAnchor">
<h2>Ejemplo<a href="adaboost.html#ejemplo-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este ejemplo se ilustra la forma de aplicar AdaBoost a un conjunto de datos bivariados para clasificar en dos clases: -1 y +1.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:adaboost01"></span>
<img src="images/adaboost01.png" alt="Datos originales." width="220" />
<p class="caption">
Figure 6.1: Datos originales.
</p>
</div>
<p>En la siguiente figura se muestran 3 clasificadores (<span class="math inline">\(h_1\)</span>, <span class="math inline">\(h_2\)</span> y <span class="math inline">\(h_3\)</span>) sencillos o árboles de profundidad uno (tocones), que fueron creados de forma secuencial. Al observar <span class="math inline">\(h1\)</span>, se nota que él clasificó mal los + encerrados en círculos. Por esa razón, en la siguiente iteración esas observaciones mal clasificadas tuvieron un mayor peso o importancia en el nuevo clasificador <span class="math inline">\(h_2\)</span>, por eso es que esos símbolos + aparecen más grandes en la segunda figura. Al mirar el clasificador <span class="math inline">\(h_2\)</span> se observa que logró clasificar bien esos + grandes, sin embargo, él clasificó mal los - que están encerrados en círculos. Por esa razón, en la siguiente iteración esas observaciones mal clasificadas tuvieron un mayor peso o importancia en el nuevo clasificador <span class="math inline">\(h_3\)</span>, por eso es que esos símbolos - aparecen más grandes en la tercera figura. El clasificador <span class="math inline">\(h_3\)</span> logra clasificar mejor esos -.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:adaboost02"></span>
<img src="images/adaboost02.png" alt="Clasificadores." width="1216" />
<p class="caption">
Figure 6.2: Clasificadores.
</p>
</div>
<p>El clasificador final (<span class="math inline">\(h_{final}\)</span>) se construye como una ponderación de los clasificadores sencillos (<span class="math inline">\(h_1\)</span>, <span class="math inline">\(h_2\)</span> y <span class="math inline">\(h_3\)</span>) como se muestra a continuación.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:adaboost03"></span>
<img src="images/adaboost03.png" alt="Obtención clasificador final." width="1850" />
<p class="caption">
Figure 6.3: Obtención clasificador final.
</p>
</div>
<p>Los valores de <span class="math inline">\(\alpha_t\)</span> son las ponderaciones que aparecen en la explicación detallada del método.</p>
</div>
<div id="ejemplo-5" class="section level2 unnumbered hasAnchor">
<h2>Ejemplo<a href="adaboost.html#ejemplo-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este ejemplo vamos a usar la base de datos <code>kyphosis</code> del paquete <strong>rpart</strong> de <span class="citation">Therneau and Atkinson (<a href="#ref-R-rpart">2023</a>)</span>. A continuación las primeras líneas de la base de datos.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="adaboost.html#cb1-1" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1-2"><a href="adaboost.html#cb1-2" tabindex="-1"></a><span class="fu">head</span>(kyphosis)</span></code></pre></div>
<pre><code>##   Kyphosis Age Number Start
## 1   absent  71      3     5
## 2   absent 158      3    14
## 3  present 128      4     5
## 4   absent   2      5     1
## 5   absent   1      4    15
## 6   absent   1      2    16</code></pre>
<p>El objetivo es crear un clasificador que use la información de Age, Number y Start para predecir el tipo de deformación kyphosis (absent or present). Como vamos a aplicar el AdaBoost manualmente debemos crear la variable respuesta con valores de -1 y 1 así:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="adaboost.html#cb3-1" tabindex="-1"></a>kyphosis<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(kyphosis<span class="sc">$</span>Kyphosis <span class="sc">==</span> <span class="st">&quot;absent&quot;</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>Vamos a crear primero un modelo de referencia <code>mod0</code> que será un árbol tradicional.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="adaboost.html#cb4-1" tabindex="-1"></a>mod0 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(y <span class="sc">~</span> Age <span class="sc">+</span> Number <span class="sc">+</span> Start, <span class="at">data=</span>kyphosis, <span class="at">method=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb4-2"><a href="adaboost.html#cb4-2" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod0, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb4-3"><a href="adaboost.html#cb4-3" tabindex="-1"></a>tabla0 <span class="ot">&lt;-</span> <span class="fu">table</span>(y0, kyphosis<span class="sc">$</span>y)</span>
<span id="cb4-4"><a href="adaboost.html#cb4-4" tabindex="-1"></a>accu_mod0 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tabla0)) <span class="sc">/</span> <span class="fu">sum</span>(tabla0)</span>
<span id="cb4-5"><a href="adaboost.html#cb4-5" tabindex="-1"></a>accu_mod0 <span class="co"># Tasa de clasificacion correcta</span></span></code></pre></div>
<pre><code>## [1] 0.8395062</code></pre>
<p>De la salida anterior podemos ver que el modelo <code>mod0</code> logró clasificar correctamente 0.8395062.</p>
<p>En el siguiente código está la implementación manual de AdaBoost, en este código se usan 20 iteraciones para crear 20 tocones (stumps) que unidos nos permitirán crear el segundo clasificador.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="adaboost.html#cb6-1" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="dv">20</span> <span class="co"># numero de iteraciones</span></span>
<span id="cb6-2"><a href="adaboost.html#cb6-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">nrow</span>(kyphosis)</span>
<span id="cb6-3"><a href="adaboost.html#cb6-3" tabindex="-1"></a>Dt <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span>m, m) <span class="co"># D1</span></span>
<span id="cb6-4"><a href="adaboost.html#cb6-4" tabindex="-1"></a>alphas <span class="ot">&lt;-</span> <span class="fu">numeric</span>(T) <span class="co"># Para almacenar alpha</span></span>
<span id="cb6-5"><a href="adaboost.html#cb6-5" tabindex="-1"></a>y_hats <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">ncol=</span>T, <span class="at">nrow=</span>m) <span class="co"># Para almacenar la predicciones</span></span>
<span id="cb6-6"><a href="adaboost.html#cb6-6" tabindex="-1"></a></span>
<span id="cb6-7"><a href="adaboost.html#cb6-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>T) {</span>
<span id="cb6-8"><a href="adaboost.html#cb6-8" tabindex="-1"></a>  mod <span class="ot">&lt;-</span> <span class="fu">rpart</span>(y <span class="sc">~</span> Age <span class="sc">+</span> Number <span class="sc">+</span> Start, <span class="at">weights=</span>Dt, <span class="at">data=</span>kyphosis, </span>
<span id="cb6-9"><a href="adaboost.html#cb6-9" tabindex="-1"></a>               <span class="at">method=</span><span class="st">&quot;class&quot;</span>, <span class="at">control=</span><span class="fu">rpart.control</span>(<span class="at">maxdepth =</span> <span class="dv">1</span>))</span>
<span id="cb6-10"><a href="adaboost.html#cb6-10" tabindex="-1"></a>  y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb6-11"><a href="adaboost.html#cb6-11" tabindex="-1"></a>  error <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(y_hat <span class="sc">==</span> kyphosis<span class="sc">$</span>y, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 1=error, 0=ok</span></span>
<span id="cb6-12"><a href="adaboost.html#cb6-12" tabindex="-1"></a>  epsilon_t <span class="ot">&lt;-</span> <span class="fu">sum</span>(error <span class="sc">*</span> Dt)</span>
<span id="cb6-13"><a href="adaboost.html#cb6-13" tabindex="-1"></a>  alpha_t <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">log</span>((<span class="dv">1</span><span class="sc">-</span>epsilon_t)<span class="sc">/</span>epsilon_t)</span>
<span id="cb6-14"><a href="adaboost.html#cb6-14" tabindex="-1"></a>  Fi <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(y_hat <span class="sc">==</span> kyphosis<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="sc">-</span>alpha_t), <span class="fu">exp</span>(alpha_t))</span>
<span id="cb6-15"><a href="adaboost.html#cb6-15" tabindex="-1"></a>  Dt <span class="ot">&lt;-</span> Dt <span class="sc">*</span> Fi</span>
<span id="cb6-16"><a href="adaboost.html#cb6-16" tabindex="-1"></a>  Dt <span class="ot">&lt;-</span> Dt <span class="sc">/</span> <span class="fu">sum</span>(Dt)</span>
<span id="cb6-17"><a href="adaboost.html#cb6-17" tabindex="-1"></a>  alphas[i] <span class="ot">&lt;-</span> alpha_t</span>
<span id="cb6-18"><a href="adaboost.html#cb6-18" tabindex="-1"></a>  y_hats[, i] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(y_hat <span class="sc">==</span> <span class="st">&quot;-1&quot;</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-19"><a href="adaboost.html#cb6-19" tabindex="-1"></a>}</span></code></pre></div>
<p>Para obtener las estimaciones con los 20 tocones se usa el siguiente código.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="adaboost.html#cb7-1" tabindex="-1"></a>y_final <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">sign</span>(y_hats <span class="sc">%*%</span> <span class="fu">matrix</span>(alphas, <span class="at">ncol=</span><span class="dv">1</span>)))</span>
<span id="cb7-2"><a href="adaboost.html#cb7-2" tabindex="-1"></a>tabla_final <span class="ot">&lt;-</span> <span class="fu">table</span>(y_final, kyphosis<span class="sc">$</span>y)</span>
<span id="cb7-3"><a href="adaboost.html#cb7-3" tabindex="-1"></a>accu_boost_manual <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tabla_final)) <span class="sc">/</span> <span class="fu">sum</span>(tabla_final)</span>
<span id="cb7-4"><a href="adaboost.html#cb7-4" tabindex="-1"></a>accu_boost_manual  <span class="co"># Tasa de clasificacion correcta</span></span></code></pre></div>
<pre><code>## [1] 0.8888889</code></pre>
<p>Por último vamos a usar la función <code>boosting</code> del paquete <strong>adabag</strong> propuesto por <span class="citation">Alfaro et al. (<a href="#ref-R-adabag">2023</a>)</span> para aplicar AdaBoost de forma automática.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="adaboost.html#cb9-1" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb9-2"><a href="adaboost.html#cb9-2" tabindex="-1"></a>adaboost <span class="ot">&lt;-</span> <span class="fu">boosting</span>(Kyphosis <span class="sc">~</span> Age <span class="sc">+</span> Number <span class="sc">+</span> Start,</span>
<span id="cb9-3"><a href="adaboost.html#cb9-3" tabindex="-1"></a>                     <span class="at">coeflearn=</span><span class="st">&quot;Freund&quot;</span>,</span>
<span id="cb9-4"><a href="adaboost.html#cb9-4" tabindex="-1"></a>                     <span class="at">data=</span>kyphosis, <span class="at">mfinal=</span><span class="dv">20</span>)</span>
<span id="cb9-5"><a href="adaboost.html#cb9-5" tabindex="-1"></a>yhat_adaboost <span class="ot">&lt;-</span> <span class="fu">predict</span>(adaboost, <span class="at">newdata=</span>kyphosis)<span class="sc">$</span>class</span>
<span id="cb9-6"><a href="adaboost.html#cb9-6" tabindex="-1"></a>tabla_adaboost <span class="ot">&lt;-</span> <span class="fu">table</span>(yhat_adaboost, kyphosis<span class="sc">$</span>Kyphosis)</span>
<span id="cb9-7"><a href="adaboost.html#cb9-7" tabindex="-1"></a>accu_boost_autom <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tabla_adaboost)) <span class="sc">/</span> <span class="fu">sum</span>(tabla_adaboost)</span>
<span id="cb9-8"><a href="adaboost.html#cb9-8" tabindex="-1"></a>accu_boost_autom  <span class="co"># Tasa de clasificacion correcta</span></span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Abajo se muestra nuevamente el código para calcular las tres tasas de clasificación correcta para el modelo de referencia, el AdaBoost manual y el AdaBoost automático.</p>
<table>
<thead>
<tr class="header">
<th>Modelo</th>
<th>Tasa de clasificación correcta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Árbol tradicional (<code>mod0</code>)</td>
<td>0.8395062</td>
</tr>
<tr class="even">
<td>AdaBoost manual</td>
<td>0.8888889</td>
</tr>
<tr class="odd">
<td>AdaBoost automático</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>De la salida anterior se observa que el árbol tradicional (<code>mod0</code>) tiene la menor tasa de clasificación correcta mientras que el modelo entrenado con <code>boosting</code> tiene la tasa de clasificación correcta mayor.</p>
</div>
<div id="ejemplo-6" class="section level2 unnumbered hasAnchor">
<h2>Ejemplo<a href="adaboost.html#ejemplo-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este ejemplo vamos a mostrar como usar el paquete <strong>adabag</strong> de <span class="citation">Alfaro et al. (<a href="#ref-R-adabag">2023</a>)</span> para aplicar AdaBoost.</p>
<p>Como ejemplo vamos a usar la base de datos <code>iris</code> en la cual se tienen 4 variables que caracterizan las flores de tres especies. En la figura de abajo se muestran las tres especies y las cuatro variables.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:iris"></span>
<img src="images/iris.png" alt="Tipos de especies y variables en la base de datos iris." width="394" />
<p class="caption">
Figure 6.4: Tipos de especies y variables en la base de datos iris.
</p>
</div>
<p>El objetivo de este ejemplo es crear un modelo para predecir la especie de una flor en función de las variables Sepal.Length y Sepal.Width.</p>
<p>Primero vamos a crear un árbol de clasificación usando el paquete <strong>rpart</strong> de <span class="citation">Therneau and Atkinson (<a href="#ref-R-rpart">2023</a>)</span>, este modelo servirá como modelo de referencia.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="adaboost.html#cb11-1" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb11-2"><a href="adaboost.html#cb11-2" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width, <span class="at">data=</span>iris)</span>
<span id="cb11-3"><a href="adaboost.html#cb11-3" tabindex="-1"></a>yhat1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod1, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span></code></pre></div>
<p>Ahora vamos a aplicar AdaBoost.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="adaboost.html#cb12-1" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb12-2"><a href="adaboost.html#cb12-2" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">boosting</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width, </span>
<span id="cb12-3"><a href="adaboost.html#cb12-3" tabindex="-1"></a>                 <span class="at">data=</span>iris, <span class="at">mfinal=</span><span class="dv">10</span>)</span>
<span id="cb12-4"><a href="adaboost.html#cb12-4" tabindex="-1"></a>yhat2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod2, <span class="at">newdata=</span>iris)<span class="sc">$</span>class</span></code></pre></div>
<p>En los objetos <code>yhat1</code> y <code>yhat2</code> están las predicciones y con ellas vamos a formar las matrices de confusión para cada modelo.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="adaboost.html#cb13-1" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">real=</span>iris<span class="sc">$</span>Species, <span class="at">prediccion=</span>yhat1)</span>
<span id="cb13-2"><a href="adaboost.html#cb13-2" tabindex="-1"></a>t1</span></code></pre></div>
<pre><code>##             prediccion
## real         setosa versicolor virginica
##   setosa         49          1         0
##   versicolor      3         31        16
##   virginica       0         11        39</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="adaboost.html#cb15-1" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">real=</span>iris<span class="sc">$</span>Species, <span class="at">prediccion=</span>yhat2)</span>
<span id="cb15-2"><a href="adaboost.html#cb15-2" tabindex="-1"></a>t2</span></code></pre></div>
<pre><code>##             prediccion
## real         setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      1         38        11
##   virginica       0         11        39</code></pre>
<p>Ahora vamos a calcular la tasa de clasificación correcta para cada una de las matrices anteriores.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="adaboost.html#cb17-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t1)) <span class="sc">/</span> <span class="fu">sum</span>(t1)</span></code></pre></div>
<pre><code>## [1] 0.7933333</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="adaboost.html#cb19-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t2)) <span class="sc">/</span> <span class="fu">sum</span>(t2)</span></code></pre></div>
<pre><code>## [1] 0.8466667</code></pre>
<p>De la anterior salida se observa que la tasa de clasificación correcta con un árbol tradicional es 79.33% mientras que con AdaBoost es 84.67%.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-R-adabag" class="csl-entry">
Alfaro, Esteban; Gamez, Matias, Garcia, Noelia; with contributions from L. Guo, A. Albano, M. Sciandra, and A. Plaia. 2023. <em>Adabag: Applies Multiclass AdaBoost.M1, SAMME and Bagging</em>. <a href="https://CRAN.R-project.org/package=adabag">https://CRAN.R-project.org/package=adabag</a>.
</div>
<div id="ref-freund_1995" class="csl-entry">
Freund, Yoav, and Robert E. Schapire. 1995. <em>A Desicion-Theoretic Generalization of on-Line Learning and an Application to Boosting</em>. Vol. 904. Springer, Berlin, Heidelberg.
</div>
<div id="ref-R-rpart" class="csl-entry">
Therneau, Terry, and Beth Atkinson. 2023. <em>Rpart: Recursive Partitioning and Regression Trees</em>. <a href="https://github.com/bethatkinson/rpart">https://github.com/bethatkinson/rpart</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="svm-clas.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="gradboost.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/fhernanb/libro_mod_pred/edit/master/81-AdaBoost.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["libro_mod_pred.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
