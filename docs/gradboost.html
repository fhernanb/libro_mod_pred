<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Gradient Boost | Modelos Predictivos</title>
  <meta name="description" content="Libro de Modelos Predictivos" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Gradient Boost | Modelos Predictivos" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Libro de Modelos Predictivos" />
  <meta name="github-repo" content="fhernanb/libro_mod_pred" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Gradient Boost | Modelos Predictivos" />
  
  <meta name="twitter:description" content="Libro de Modelos Predictivos" />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Freddy Hernández" />


<meta name="date" content="2020-10-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="adaboost.html"/>
<link rel="next" href="reg-versus-arb.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Predictivos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenido</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-libro"><i class="fa fa-check"></i>Estructura del libro</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-y-convenciones"><i class="fa fa-check"></i>Software y convenciones</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bloques-informativos"><i class="fa fa-check"></i>Bloques informativos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="arb-de-regre.html"><a href="arb-de-regre.html"><i class="fa fa-check"></i><b>1</b> Árboles de regresión</a><ul>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árboles"><i class="fa fa-check"></i>Árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árbol-de-decisión"><i class="fa fa-check"></i>Árbol de decisión</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#tipos-de-árboles"><i class="fa fa-check"></i>Tipos de árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#árbol-de-regresión"><i class="fa fa-check"></i>Árbol de regresión</a></li>
<li class="chapter" data-level="" data-path="arb-de-regre.html"><a href="arb-de-regre.html#paquetes-de-r-para-árboles"><i class="fa fa-check"></i>Paquetes de R para árboles</a></li>
<li><a href="arb-de-regre.html#paquete-rpart">Paquete <strong>rpart</strong></a></li>
<li><a href="arb-de-regre.html#paquete-tree">Paquete <strong>tree</strong></a></li>
<li><a href="arb-de-regre.html#ejemplo-con-el-paquete-rpart">Ejemplo con el paquete <strong>rpart</strong></a></li>
<li><a href="arb-de-regre.html#ejemplo-con-el-paquete-tree">Ejemplo con el paquete <strong>tree</strong></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html"><i class="fa fa-check"></i><b>2</b> Árboles de clasificación</a><ul>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árboles-1"><i class="fa fa-check"></i>Árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árbol-de-decisión-1"><i class="fa fa-check"></i>Árbol de decisión</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#tipos-de-árboles-1"><i class="fa fa-check"></i>Tipos de árboles</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#árbol-de-clasificación"><i class="fa fa-check"></i>Árbol de clasificación</a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#paquetes-de-r-para-construir-árboles"><i class="fa fa-check"></i>Paquetes de R para construir árboles</a></li>
<li><a href="arb-de-clasif.html#ejemplo-con-rpart">Ejemplo con <strong>rpart</strong></a></li>
<li><a href="arb-de-clasif.html#ejemplo-con-tree">Ejemplo con <strong>tree</strong></a></li>
<li class="chapter" data-level="" data-path="arb-de-clasif.html"><a href="arb-de-clasif.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="svm-reg.html"><a href="svm-reg.html"><i class="fa fa-check"></i><b>3</b> Support Vector Machines para regresión</a><ul>
<li class="chapter" data-level="" data-path="svm-reg.html"><a href="svm-reg.html#paquetes-de-r-para-svm"><i class="fa fa-check"></i>Paquetes de R para svm</a></li>
<li class="chapter" data-level="" data-path="svm-reg.html"><a href="svm-reg.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="svm-clas.html"><a href="svm-clas.html"><i class="fa fa-check"></i><b>4</b> Support Vector Machines para clasificación</a><ul>
<li class="chapter" data-level="" data-path="svm-clas.html"><a href="svm-clas.html#paquetes-de-r-para-svm-1"><i class="fa fa-check"></i>Paquetes de R para svm</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="adaboost.html"><a href="adaboost.html"><i class="fa fa-check"></i><b>5</b> AdaBoost</a><ul>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#explicación-sencilla-de-adaboost"><i class="fa fa-check"></i>Explicación sencilla de AdaBoost</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#explicación-detallada-de-adaboost"><i class="fa fa-check"></i>Explicación detallada de AdaBoost</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-1"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-2"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-3"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="adaboost.html"><a href="adaboost.html#ejemplo-4"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gradboost.html"><a href="gradboost.html"><i class="fa fa-check"></i><b>6</b> Gradient Boost</a><ul>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-5"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-6"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="gradboost.html"><a href="gradboost.html#ejemplo-7"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html"><i class="fa fa-check"></i><b>7</b> Regresión lineal versus árboles de regresión</a><ul>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#regresión-lineal"><i class="fa fa-check"></i>Regresión lineal</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#arboles-de-regresión"><i class="fa fa-check"></i>Arboles de regresión</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#ejemplo-8"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#estudio-de-simulación-para-comparar-ambos-métodos"><i class="fa fa-check"></i>Estudio de simulación para comparar ambos métodos</a></li>
<li class="chapter" data-level="" data-path="reg-versus-arb.html"><a href="reg-versus-arb.html#retos"><i class="fa fa-check"></i>Retos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Predictivos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gradboost" class="section level1">
<h1><span class="header-section-number">6</span> Gradient Boost</h1>
<p>Gradient Boost fue propuesto por <span class="citation">(Friedman <a href="#ref-Friedman1999a" role="doc-biblioref">1999</a><a href="#ref-Friedman1999a" role="doc-biblioref">a</a>)</span> y <span class="citation">(Friedman <a href="#ref-Friedman1999b" role="doc-biblioref">1999</a><a href="#ref-Friedman1999b" role="doc-biblioref">b</a>)</span> y consiste en crear varios predictores en secuencia. El primer predictor usa la media de la variable <span class="math inline">\(Y\)</span> para predecir, luego el segundo predictor explica los errores del primer predictor, el tercer predictor explicar los erroes del segundo predictor y así sucesivamente. En la siguiente figura se muestra una ilustración de lo que es Gradient Boost.</p>
<p align="center">
<img src="images/gradboost_illustration.png" width="700">
</p>
<div id="ejemplo-5" class="section level2 unnumbered">
<h2>Ejemplo</h2>
<p>Abajo se presenta un video con una explicación detallada de lo que es Gradient Boost.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/3CC4N4z3GJc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="ejemplo-6" class="section level2 unnumbered">
<h2>Ejemplo</h2>
<p>En este ejemplo se muestra como aplicar Gradient Boost de forma manual usando los datos del video anterior.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="gradboost.html#cb86-1"></a>height &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.6</span>, <span class="fl">1.6</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">1.5</span>, <span class="fl">1.4</span>)</span>
<span id="cb86-2"><a href="gradboost.html#cb86-2"></a>color &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb86-3"><a href="gradboost.html#cb86-3"></a>gender &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>, <span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>, <span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)</span>
<span id="cb86-4"><a href="gradboost.html#cb86-4"></a>weigth &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">88</span>, <span class="dv">76</span>, <span class="dv">56</span>, <span class="dv">73</span>, <span class="dv">77</span>, <span class="dv">57</span>)</span></code></pre></div>
<p>La librería para crear los árboles será <strong>rpart</strong>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="gradboost.html#cb87-1"></a><span class="kw">library</span>(rpart)</span></code></pre></div>
<p>El valor learning rate en el ejemplo será <span class="math inline">\(\alpha=0.10\)</span>. A continuación el código para crear el modelo inicial y los modelos siguientes del video anterior.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="gradboost.html#cb88-1"></a>a &lt;-<span class="st"> </span><span class="fl">0.1</span> <span class="co"># Learning rate</span></span>
<span id="cb88-2"><a href="gradboost.html#cb88-2"></a></span>
<span id="cb88-3"><a href="gradboost.html#cb88-3"></a><span class="co"># Modelo inicial</span></span>
<span id="cb88-4"><a href="gradboost.html#cb88-4"></a>res1 &lt;-<span class="st"> </span>weigth <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(weigth)</span>
<span id="cb88-5"><a href="gradboost.html#cb88-5"></a></span>
<span id="cb88-6"><a href="gradboost.html#cb88-6"></a><span class="co"># Modelo 2</span></span>
<span id="cb88-7"><a href="gradboost.html#cb88-7"></a>mod2 &lt;-<span class="st"> </span><span class="kw">rpart</span>(res1 <span class="op">~</span><span class="st"> </span>height <span class="op">+</span><span class="st"> </span>color <span class="op">+</span><span class="st"> </span>gender,</span>
<span id="cb88-8"><a href="gradboost.html#cb88-8"></a>              <span class="dt">control=</span><span class="kw">rpart.control</span>(<span class="dt">minsplit =</span> <span class="dv">3</span>))</span>
<span id="cb88-9"><a href="gradboost.html#cb88-9"></a>res2 &lt;-<span class="st"> </span>weigth <span class="op">-</span><span class="st"> </span>(<span class="kw">mean</span>(weigth) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">predict</span>(mod2))</span>
<span id="cb88-10"><a href="gradboost.html#cb88-10"></a></span>
<span id="cb88-11"><a href="gradboost.html#cb88-11"></a><span class="co"># Modelo 3</span></span>
<span id="cb88-12"><a href="gradboost.html#cb88-12"></a>mod3 &lt;-<span class="st"> </span><span class="kw">rpart</span>(res2 <span class="op">~</span><span class="st"> </span>height <span class="op">+</span><span class="st"> </span>color <span class="op">+</span><span class="st"> </span>gender,</span>
<span id="cb88-13"><a href="gradboost.html#cb88-13"></a>              <span class="dt">control=</span><span class="kw">rpart.control</span>(<span class="dt">minsplit =</span> <span class="dv">3</span>))</span>
<span id="cb88-14"><a href="gradboost.html#cb88-14"></a>res3 &lt;-<span class="st"> </span>weigth <span class="op">-</span><span class="st"> </span>(<span class="kw">mean</span>(weigth) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">predict</span>(mod2) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">predict</span>(mod3))</span></code></pre></div>
<p>A continuación una tabla con los residuales de los modelos.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="gradboost.html#cb89-1"></a><span class="kw">cbind</span>(res1, res2, res3)</span></code></pre></div>
<pre><code>##         res1   res2    res3
## 1  16.833333  15.15  13.635
## 2   4.833333   4.35   3.915
## 3 -15.166667 -13.70 -12.380
## 4   1.833333   1.45   1.105
## 5   5.833333   5.45   5.105
## 6 -14.166667 -12.70 -11.380</code></pre>
<p>Para predecir el valor de weigth cuando height=1.7, color=“green” y gender=“male” se usa el siguiente código.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="gradboost.html#cb91-1"></a>new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">height=</span><span class="fl">1.7</span>, <span class="dt">color=</span><span class="st">&quot;green&quot;</span>, <span class="dt">gender=</span><span class="st">&quot;female&quot;</span>)</span>
<span id="cb91-2"><a href="gradboost.html#cb91-2"></a><span class="kw">mean</span>(weigth) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">predict</span>(mod2, new_data) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">predict</span>(mod3, new_data)</span></code></pre></div>
<pre><code>##      1 
## 72.085</code></pre>
</div>
<div id="ejemplo-7" class="section level2 unnumbered">
<h2>Ejemplo</h2>
<p>En este ejemplo se van a usar los datos <code>Boston</code> del paquete <span class="citation">(Ripley <a href="#ref-R-MASS" role="doc-biblioref">2020</a>)</span> para predecir la variable <code>medv</code> en función de las otras covariables.</p>
<p>Para explorar la base de datos usamos el siguiente código.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="gradboost.html#cb93-1"></a><span class="kw">library</span>(MASS)</span>
<span id="cb93-2"><a href="gradboost.html#cb93-2"></a><span class="kw">str</span>(Boston)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ black  : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<p>Vamos a crear dos conjuntos de datos, uno de entrenamiento y otro de validación de la siguiente manera.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="gradboost.html#cb95-1"></a><span class="kw">library</span>(caret)</span>
<span id="cb95-2"><a href="gradboost.html#cb95-2"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb95-3"><a href="gradboost.html#cb95-3"></a>indexes &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(Boston<span class="op">$</span>medv, <span class="dt">p =</span> <span class="fl">.90</span>, <span class="dt">list =</span> F)</span>
<span id="cb95-4"><a href="gradboost.html#cb95-4"></a>train &lt;-<span class="st"> </span>Boston[indexes, ]</span>
<span id="cb95-5"><a href="gradboost.html#cb95-5"></a>test &lt;-<span class="st"> </span>Boston[<span class="op">-</span>indexes, ]</span></code></pre></div>
<p>El primer modelo predictivo será un árbol sencillo que nos servirá como elemento de comparación.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="gradboost.html#cb96-1"></a><span class="kw">library</span>(rpart)</span>
<span id="cb96-2"><a href="gradboost.html#cb96-2"></a>model_tree &lt;-<span class="st"> </span><span class="kw">rpart</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>train)</span></code></pre></div>
<p>Ahora vamos a calcular el <span class="math inline">\(RMSE\)</span> (root mean square error) y la correlación entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="gradboost.html#cb97-1"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(model_tree)</span>
<span id="cb97-2"><a href="gradboost.html#cb97-2"></a><span class="kw">sqrt</span>(<span class="kw">sum</span>((train<span class="op">$</span>medv <span class="op">-</span><span class="st"> </span>y_hat)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 83.63843</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="gradboost.html#cb99-1"></a><span class="kw">cor</span>(train<span class="op">$</span>medv, y_hat)</span></code></pre></div>
<pre><code>## [1] 0.9070587</code></pre>
<p>Para comparar los resultados del modelo vamos a crear un diagrama de dispersión entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="gradboost.html#cb101-1"></a><span class="kw">plot</span>(<span class="dt">x=</span>train<span class="op">$</span>medv, <span class="dt">y=</span>y_hat, <span class="dt">xlab=</span><span class="st">&#39;Valor observado&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicción&#39;)</span></span>
<span id="cb101-2"><a href="gradboost.html#cb101-2"></a><span class="st">abline(a=0, b=1, lty=&#39;</span>dashed<span class="st">&#39;)</span></span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost1-1.png" width="672" /></p>
<p>Ahora vamos a usar la función <code>gbm</code> del paquete <span class="citation">(Greenwell et al. <a href="#ref-R-gbm" role="doc-biblioref">2020</a>)</span> para aplicar el algoritmo Gradient Boost con <span class="math inline">\(\alpha=0.01\)</span>, 5000 árboles (iteraciones) y una profundidad de 1 en cada árbol (stump).</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="gradboost.html#cb102-1"></a><span class="kw">library</span>(gbm)</span>
<span id="cb102-2"><a href="gradboost.html#cb102-2"></a><span class="kw">set.seed</span>(<span class="dv">123</span>) <span class="co"># for reproducibility</span></span>
<span id="cb102-3"><a href="gradboost.html#cb102-3"></a>model_gbm1 &lt;-<span class="st"> </span><span class="kw">gbm</span>(medv <span class="op">~</span>., <span class="dt">data =</span> train,</span>
<span id="cb102-4"><a href="gradboost.html#cb102-4"></a>                  <span class="dt">distribution=</span><span class="st">&quot;gaussian&quot;</span>, <span class="dt">cv.folds=</span><span class="dv">5</span>, </span>
<span id="cb102-5"><a href="gradboost.html#cb102-5"></a>                  <span class="dt">shrinkage=</span><span class="fl">0.01</span>, <span class="dt">n.minobsinnode=</span><span class="dv">10</span>,</span>
<span id="cb102-6"><a href="gradboost.html#cb102-6"></a>                  <span class="dt">n.trees=</span><span class="dv">5000</span>, <span class="dt">interaction.depth=</span><span class="dv">1</span>)</span>
<span id="cb102-7"><a href="gradboost.html#cb102-7"></a><span class="kw">print</span>(model_gbm1)</span></code></pre></div>
<pre><code>## gbm(formula = medv ~ ., distribution = &quot;gaussian&quot;, data = train, 
##     n.trees = 5000, interaction.depth = 1, n.minobsinnode = 10, 
##     shrinkage = 0.01, cv.folds = 5)
## A gradient boosted model with gaussian loss function.
## 5000 iterations were performed.
## The best cross-validation iteration was 4404.
## There were 13 predictors of which 13 had non-zero influence.</code></pre>
<p>Ahora vamos a calcular el <span class="math inline">\(RMSE\)</span> (root mean square error) y la correlación entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="gradboost.html#cb104-1"></a><span class="kw">sqrt</span>(<span class="kw">min</span>(model_gbm1<span class="op">$</span>cv.error))</span></code></pre></div>
<pre><code>## [1] 3.636371</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="gradboost.html#cb106-1"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(model_gbm1)</span></code></pre></div>
<pre><code>## Using 4404 trees...</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="gradboost.html#cb108-1"></a><span class="kw">cor</span>(train<span class="op">$</span>medv, y_hat)</span></code></pre></div>
<pre><code>## [1] 0.9542746</code></pre>
<p>Para comparar los resultados del modelo vamos a crear un diagrama de dispersión entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="gradboost.html#cb110-1"></a><span class="kw">plot</span>(<span class="dt">x=</span>train<span class="op">$</span>medv, <span class="dt">y=</span>y_hat, <span class="dt">xlab=</span><span class="st">&#39;Valor observado&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicción&#39;)</span></span>
<span id="cb110-2"><a href="gradboost.html#cb110-2"></a><span class="st">abline(a=0, b=1, lty=&#39;</span>dashed<span class="st">&#39;)</span></span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost2-1.png" width="672" /></p>
<p>Al comparar la correlación y los diagramas de dispersión se observa una mejora considerable con el modelo Gradient Boost.</p>
<p>Podemos construir una figura para observar la evolución del <span class="math inline">\(RMSE\)</span> en función del número de árboles (iteraciones).</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="gradboost.html#cb111-1"></a><span class="kw">gbm.perf</span>(model_gbm1, <span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>)</span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost3-1.png" width="672" /></p>
<pre><code>## [1] 4404</code></pre>
<p>De la figura anterior se observa que en la iteración 4404 (linea azul a trazos) fue donde se obtuvo el menor <span class="math inline">\(RMSE\)</span>.</p>
<p>Vamos a crear otro modelo de predicción pero cambiando algunos de los hiper-parámetros, <span class="math inline">\(\alpha=0.15\)</span> y una profundidad de 3 en cada árbol.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="gradboost.html#cb113-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb113-2"><a href="gradboost.html#cb113-2"></a>model_gbm2 &lt;-<span class="st"> </span><span class="kw">gbm</span>(medv <span class="op">~</span>., <span class="dt">data =</span> train,</span>
<span id="cb113-3"><a href="gradboost.html#cb113-3"></a>                  <span class="dt">distribution=</span><span class="st">&quot;gaussian&quot;</span>, <span class="dt">cv.folds=</span><span class="dv">5</span>, </span>
<span id="cb113-4"><a href="gradboost.html#cb113-4"></a>                  <span class="dt">shrinkage=</span><span class="fl">0.15</span>, <span class="dt">n.minobsinnode=</span><span class="dv">10</span>,</span>
<span id="cb113-5"><a href="gradboost.html#cb113-5"></a>                  <span class="dt">n.trees=</span><span class="dv">5000</span>, <span class="dt">interaction.depth=</span><span class="dv">3</span>)</span></code></pre></div>
<p>Ahora vamos a calcular el <span class="math inline">\(RMSE\)</span> (root mean square error) y la correlación entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="gradboost.html#cb114-1"></a><span class="kw">sqrt</span>(<span class="kw">min</span>(model_gbm2<span class="op">$</span>cv.error))</span></code></pre></div>
<pre><code>## [1] 3.370139</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="gradboost.html#cb116-1"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(model_gbm2)</span></code></pre></div>
<pre><code>## Using 241 trees...</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="gradboost.html#cb118-1"></a><span class="kw">cor</span>(train<span class="op">$</span>medv, y_hat)</span></code></pre></div>
<pre><code>## [1] 0.9852213</code></pre>
<p>Para comparar los resultados del modelo vamos a crear un diagrama de dispersión entre <span class="math inline">\(y\)</span> y <span class="math inline">\(\hat{y}\)</span>.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="gradboost.html#cb120-1"></a><span class="kw">plot</span>(<span class="dt">x=</span>train<span class="op">$</span>medv, <span class="dt">y=</span>y_hat, <span class="dt">xlab=</span><span class="st">&#39;Valor observado&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicción&#39;)</span></span>
<span id="cb120-2"><a href="gradboost.html#cb120-2"></a><span class="st">abline(a=0, b=1, lty=&#39;</span>dashed<span class="st">&#39;)</span></span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost4-1.png" width="672" /></p>
<p>Podemos construir una figura para observar la evolución del <span class="math inline">\(RMSE\)</span> en función del número de árboles (iteraciones).</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="gradboost.html#cb121-1"></a><span class="kw">gbm.perf</span>(model_gbm2, <span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>)</span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost5-1.png" width="672" /></p>
<pre><code>## [1] 241</code></pre>
<p>En lugar de buscar esos hiper-parámetros a manualmente, podemos hacer una búsqueda automática creando un conjunto de posibles valores de los hiper-parámetros así.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="gradboost.html#cb123-1"></a><span class="co"># create hyperparameter grid</span></span>
<span id="cb123-2"><a href="gradboost.html#cb123-2"></a>hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb123-3"><a href="gradboost.html#cb123-3"></a>  <span class="dt">shrinkage =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>),</span>
<span id="cb123-4"><a href="gradboost.html#cb123-4"></a>  <span class="dt">interaction.depth =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>),</span>
<span id="cb123-5"><a href="gradboost.html#cb123-5"></a>  <span class="dt">n.minobsinnode =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>),</span>
<span id="cb123-6"><a href="gradboost.html#cb123-6"></a>  <span class="dt">bag.fraction =</span> <span class="kw">c</span>(<span class="fl">0.65</span>, <span class="fl">0.8</span>, <span class="dv">1</span>), </span>
<span id="cb123-7"><a href="gradboost.html#cb123-7"></a>  <span class="dt">optimal_trees =</span> <span class="dv">0</span>,               <span class="co"># a place to dump results</span></span>
<span id="cb123-8"><a href="gradboost.html#cb123-8"></a>  <span class="dt">min_RMSE =</span> <span class="dv">0</span>,                    <span class="co"># a place to dump results</span></span>
<span id="cb123-9"><a href="gradboost.html#cb123-9"></a>  <span class="dt">min_cor =</span> <span class="dv">0</span></span>
<span id="cb123-10"><a href="gradboost.html#cb123-10"></a>)</span>
<span id="cb123-11"><a href="gradboost.html#cb123-11"></a></span>
<span id="cb123-12"><a href="gradboost.html#cb123-12"></a><span class="kw">nrow</span>(hyper_grid) <span class="co"># total number of combinations</span></span></code></pre></div>
<pre><code>## [1] 81</code></pre>
<p>Para hacer la búsqueda usamos el siguiente código.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="gradboost.html#cb125-1"></a><span class="co"># randomize data</span></span>
<span id="cb125-2"><a href="gradboost.html#cb125-2"></a>random_index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train), <span class="kw">nrow</span>(train))</span>
<span id="cb125-3"><a href="gradboost.html#cb125-3"></a>random_train &lt;-<span class="st"> </span>train[random_index, ]</span>
<span id="cb125-4"><a href="gradboost.html#cb125-4"></a></span>
<span id="cb125-5"><a href="gradboost.html#cb125-5"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(hyper_grid)) {</span>
<span id="cb125-6"><a href="gradboost.html#cb125-6"></a>  <span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb125-7"><a href="gradboost.html#cb125-7"></a>  gbm.tune &lt;-<span class="st"> </span><span class="kw">gbm</span>(</span>
<span id="cb125-8"><a href="gradboost.html#cb125-8"></a>    <span class="dt">formula =</span> medv <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb125-9"><a href="gradboost.html#cb125-9"></a>    <span class="dt">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb125-10"><a href="gradboost.html#cb125-10"></a>    <span class="dt">data =</span> random_train,</span>
<span id="cb125-11"><a href="gradboost.html#cb125-11"></a>    <span class="dt">n.trees =</span> <span class="dv">5000</span>,</span>
<span id="cb125-12"><a href="gradboost.html#cb125-12"></a>    <span class="dt">interaction.depth =</span> hyper_grid<span class="op">$</span>interaction.depth[i],</span>
<span id="cb125-13"><a href="gradboost.html#cb125-13"></a>    <span class="dt">shrinkage =</span> hyper_grid<span class="op">$</span>shrinkage[i],</span>
<span id="cb125-14"><a href="gradboost.html#cb125-14"></a>    <span class="dt">n.minobsinnode =</span> hyper_grid<span class="op">$</span>n.minobsinnode[i],</span>
<span id="cb125-15"><a href="gradboost.html#cb125-15"></a>    <span class="dt">bag.fraction =</span> hyper_grid<span class="op">$</span>bag.fraction[i],</span>
<span id="cb125-16"><a href="gradboost.html#cb125-16"></a>    <span class="dt">train.fraction =</span> <span class="fl">0.75</span>,</span>
<span id="cb125-17"><a href="gradboost.html#cb125-17"></a>    <span class="dt">n.cores =</span> <span class="ot">NULL</span>, <span class="co"># will use all cores by default</span></span>
<span id="cb125-18"><a href="gradboost.html#cb125-18"></a>    <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb125-19"><a href="gradboost.html#cb125-19"></a>  )</span>
<span id="cb125-20"><a href="gradboost.html#cb125-20"></a>  </span>
<span id="cb125-21"><a href="gradboost.html#cb125-21"></a>  <span class="co"># agregando la inf que nos interesa</span></span>
<span id="cb125-22"><a href="gradboost.html#cb125-22"></a>  hyper_grid<span class="op">$</span>optimal_trees[i] &lt;-<span class="st"> </span><span class="kw">which.min</span>(gbm.tune<span class="op">$</span>valid.error)</span>
<span id="cb125-23"><a href="gradboost.html#cb125-23"></a>  hyper_grid<span class="op">$</span>min_RMSE[i] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">min</span>(gbm.tune<span class="op">$</span>valid.error))</span>
<span id="cb125-24"><a href="gradboost.html#cb125-24"></a>  hyper_grid<span class="op">$</span>min_cor[i] &lt;-<span class="st"> </span><span class="kw">cor</span>(random_train<span class="op">$</span>medv, <span class="kw">predict</span>(gbm.tune))</span>
<span id="cb125-25"><a href="gradboost.html#cb125-25"></a>}</span></code></pre></div>
<p>Organizamos los resultados en relación al menor <span class="math inline">\(RMSE\)</span>.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="gradboost.html#cb126-1"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb126-2"><a href="gradboost.html#cb126-2"></a>hyper_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb126-3"><a href="gradboost.html#cb126-3"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">arrange</span>(min_RMSE) <span class="op">%&gt;%</span></span>
<span id="cb126-4"><a href="gradboost.html#cb126-4"></a><span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##    shrinkage interaction.depth n.minobsinnode bag.fraction optimal_trees
## 1       0.30                 5              5         0.80            88
## 2       0.30                 5              5         0.65           127
## 3       0.01                 5              5         0.80          3019
## 4       0.01                 3              5         0.65          4897
## 5       0.01                 5              5         0.65          4137
## 6       0.10                 5              5         1.00           128
## 7       0.01                 3              5         0.80          4884
## 8       0.01                 5              5         1.00          2543
## 9       0.01                 3             10         0.80          4984
## 10      0.01                 5             10         0.80          3699
##    min_RMSE   min_cor
## 1  2.685273 0.9862784
## 2  2.729782 0.9869481
## 3  2.778927 0.9869945
## 4  2.782291 0.9853981
## 5  2.796934 0.9876546
## 6  2.800982 0.9803835
## 7  2.837197 0.9852038
## 8  2.837520 0.9855254
## 9  2.860405 0.9838807
## 10 2.870885 0.9860587</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="gradboost.html#cb128-1"></a><span class="co"># for reproducibility</span></span>
<span id="cb128-2"><a href="gradboost.html#cb128-2"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb128-3"><a href="gradboost.html#cb128-3"></a></span>
<span id="cb128-4"><a href="gradboost.html#cb128-4"></a><span class="co"># train GBM model</span></span>
<span id="cb128-5"><a href="gradboost.html#cb128-5"></a>gbm.fit.final &lt;-<span class="st"> </span><span class="kw">gbm</span>(</span>
<span id="cb128-6"><a href="gradboost.html#cb128-6"></a>  <span class="dt">formula =</span> medv <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb128-7"><a href="gradboost.html#cb128-7"></a>  <span class="dt">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb128-8"><a href="gradboost.html#cb128-8"></a>  <span class="dt">data =</span> train,</span>
<span id="cb128-9"><a href="gradboost.html#cb128-9"></a>  <span class="dt">n.trees =</span> <span class="dv">88</span>,</span>
<span id="cb128-10"><a href="gradboost.html#cb128-10"></a>  <span class="dt">interaction.depth =</span> <span class="dv">5</span>,</span>
<span id="cb128-11"><a href="gradboost.html#cb128-11"></a>  <span class="dt">shrinkage =</span> <span class="fl">0.3</span>,</span>
<span id="cb128-12"><a href="gradboost.html#cb128-12"></a>  <span class="dt">n.minobsinnode =</span> <span class="dv">5</span>,</span>
<span id="cb128-13"><a href="gradboost.html#cb128-13"></a>  <span class="dt">bag.fraction =</span> <span class="fl">0.80</span>, </span>
<span id="cb128-14"><a href="gradboost.html#cb128-14"></a>  <span class="dt">train.fraction =</span> <span class="dv">1</span>,</span>
<span id="cb128-15"><a href="gradboost.html#cb128-15"></a>  <span class="dt">n.cores =</span> <span class="ot">NULL</span>, <span class="co"># will use all cores by default</span></span>
<span id="cb128-16"><a href="gradboost.html#cb128-16"></a>  <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb128-17"><a href="gradboost.html#cb128-17"></a>  ) </span></code></pre></div>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="gradboost.html#cb129-1"></a><span class="kw">summary</span>(gbm.fit.final, <span class="dt">cBars =</span> <span class="dv">10</span>,</span>
<span id="cb129-2"><a href="gradboost.html#cb129-2"></a>        <span class="dt">method =</span> relative.influence, <span class="dt">las =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost6-1.png" width="672" /></p>
<pre><code>##             var     rel.inf
## rm           rm 40.70059606
## lstat     lstat 36.67225822
## dis         dis  8.03512644
## crim       crim  4.10937068
## nox         nox  3.99034366
## ptratio ptratio  2.13830279
## age         age  1.34811594
## black     black  1.16184689
## tax         tax  1.14437416
## indus     indus  0.37045656
## rad         rad  0.21608957
## zn           zn  0.07111692
## chas       chas  0.04200211</code></pre>
<p><a href="http://uc-r.github.io/gbm_regression" class="uri">http://uc-r.github.io/gbm_regression</a></p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="gradboost.html#cb131-1"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object=</span>gbm.fit.final, </span>
<span id="cb131-2"><a href="gradboost.html#cb131-2"></a>                 <span class="dt">newdata=</span>test, <span class="dt">n.trees =</span> <span class="dv">88</span>)</span>
<span id="cb131-3"><a href="gradboost.html#cb131-3"></a><span class="kw">cor</span>(test<span class="op">$</span>medv, y_hat)</span></code></pre></div>
<pre><code>## [1] 0.934735</code></pre>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="gradboost.html#cb133-1"></a><span class="kw">plot</span>(<span class="dt">x=</span>test<span class="op">$</span>medv, <span class="dt">y=</span>y_hat, <span class="dt">xlab=</span><span class="st">&#39;Valor observado&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicción&#39;)</span></span>
<span id="cb133-2"><a href="gradboost.html#cb133-2"></a><span class="st">abline(a=0, b=1, lty=&#39;</span>dashed<span class="st">&#39;)</span></span></code></pre></div>
<p><img src="libro_mod_pred_files/figure-html/gradboost7-1.png" width="672" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Friedman1999a">
<p>Friedman, J. H. 1999a. “Greedy Function Approximation: A Gradient Boosting Machine.” Stanford University.</p>
</div>
<div id="ref-Friedman1999b">
<p>Friedman, J. 1999b. “Stochastic Gradient Boosting.” Stanford University.</p>
</div>
<div id="ref-R-gbm">
<p>Greenwell, Brandon, Bradley Boehmke, Jay Cunningham, and GBM Developers. 2020. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
<div id="ref-R-MASS">
<p>Ripley, Brian. 2020. <em>MASS: Support Functions and Datasets for Venables and Ripley’s Mass</em>. <a href="https://CRAN.R-project.org/package=MASS">https://CRAN.R-project.org/package=MASS</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="adaboost.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="reg-versus-arb.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/fhernanb/libro_mod_pred/edit/master/82-GradBoost.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
