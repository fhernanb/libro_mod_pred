[["arb-distri.html", "3 Árboles de regresión distribucionales Videos útiles Paquete disttree Ejemplo Ejemplo Ejemplo", " 3 Árboles de regresión distribucionales Los árboles de regresión distribucionales fueron propuestos en Schlosser et al. (2019) y Schlosser (2020). Esta nueva propuesta unifica dos aproximaciones de modelación: Data modeling. Algorithmic modeling. Abajo una comparación entre un árbol de regresión y un árbol de regresión distribucional. Videos útiles Paquete disttree distree (Schlosser et al. 2021) es un paquete de R para ajustar árboles y bosques de regresión distribucionales basado en la estimación de máxima verosimilitud de parámetros para familias de distribución específicas. Para instalar el paquete puedes usar el siguiente código. install.packages(&quot;disttree&quot;, repos=&quot;http://R-Forge.R-project.org&quot;) Para crear un árbol de regresión distribucional se usa la función disttree que tiene la siguiente estructura. disttree(formula, data, subset, na.action = na.pass, weights, offset, cluster, family = NO(), control = disttree_control(...), converged = NULL, scores = NULL, doFit = TRUE, ...) El argumento family se utiliza para indicar la distribución estadística que se asume para la variable respuesta \\(Y\\). Se puede elegir cualquier distribución de gamlss (Stasinopoulos and Rigby 2023) o cualquier distribución de los paquetes RelDists (Hernandez et al. 2022) RealDists y DiscreteDists. Una pregunta frecuente es ¿cómo selecciono la distribución que mejor explica el patrón de mi variable respuesta \\(Y\\)? Para encontrar las distribuciones que mejor explican a \\(Y\\) se puede utilizar el procedimiento mostrado en este documento. Ejemplo Este ejemplo está basado en la figura 1.2 de la disertación de Schlosser (2020). Aquí vamos a tener una variable respuesta \\(Y\\) con distribución normal pero que depende de la variable auxiliar \\(X\\). \\[\\begin{equation*} Y = \\begin{cases} N(\\mu=5, \\sigma=1) \\, \\text{si $x &lt; 0.4$,} \\\\ N(\\mu=12, \\sigma=2) \\, \\text{si $0.4 \\leq x \\leq 0.8$,} \\\\ N(\\mu=0, \\sigma=0.5) \\, \\text{si $x &gt; 0.8$}. \\end{cases} \\end{equation*}\\] El siguiente código sirve para simular los datos. n &lt;- 500 x &lt;- runif(n=n) y &lt;- numeric(n) y[x &lt; 0.4] &lt;- rnorm(n=sum(x &lt; 0.4), mean=5, sd=1) y[x &gt;+ 0.4 &amp; x &lt; 0.8] &lt;- rnorm(n=sum(x &gt;+ 0.4 &amp; x &lt; 0.8), mean=12, sd=2) y[x &gt;= 0.8] &lt;- rnorm(n=sum(x &gt;= 0.8), mean=0, sd=0.5) datos &lt;- data.frame(y=y, x=x) plot(x=x, y=y, ylim=c(-5, 20)) Vamos ahora a crear el árbol distribucional con family=NO. library(disttree) mod &lt;- disttree(y ~ x, data=datos, family=NO) plot(mod) ¿Cuál será el valor estimado de \\(Y\\) para tres nuevos objetos que tiene valor de \\(x=0.35\\), \\(x=0.47\\) y \\(x=0.89\\) respectivamente? new_data &lt;- data.frame(x=c(0.35, 0.47, 0.89)) predicciones &lt;- predict(mod, newdata=new_data) predicciones ## mu sigma ## 1 4.98323139 1.0660323 ## 2 12.04733366 2.0761440 ## 3 0.02621348 0.4960054 Ejemplo Este ejemplo está basado en un ejemplo de esta presentación de Achim Zeileis. El modelo estadístico para simular los datos es el siguiente: El siguiente código sirve para simular los datos. n &lt;- 300 k &lt;- 2 x &lt;- runif(n=n, min=-0.4, max=1) media &lt;- 10 * exp(-(4*x-2)^(2*k)) desvi &lt;- 0.5 + 2 * abs(x) y &lt;- rnorm(n=n, mean=media, sd=desvi) datos &lt;- data.frame(y, x) library(disttree) mod &lt;- disttree(y ~ x, data=datos, family=NO) plot(mod) Ejemplo Este ejemplo se parece el ejemplo inicial, sólo que aquí la variable respuesta \\(Y\\) va a tener distribución FWE (Flexible Weibull Extension) y vamos a construir tres árboles distribucionales con familia NO, FWE y WEI. El objetivo es saber si disttree logra indicarnos cuál árbol distribucional es el más apropiado. El modelo del cuál vamos a generar los datos es el siguiente: \\[\\begin{equation*} Y = \\begin{cases} FWE(\\mu=0.7, \\sigma=1) \\, \\text{si $x &lt; 0.4$,} \\\\ FWE(\\mu=0.4, \\sigma=2) \\, \\text{si $0.4 \\leq x \\leq 0.8$,} \\\\ FWE(\\mu=0.5, \\sigma=0.5) \\, \\text{si $x &gt; 0.8$}. \\end{cases} \\end{equation*}\\] El código para simular los datos es el siguiente: library(RelDists) # Para usar la distribucion FWE n &lt;- 500 x &lt;- runif(n=n) y &lt;- numeric(n) y[x &lt; 0.4] &lt;- rFWE(n=sum(x &lt; 0.4), mu=0.7, sigma=1) y[x &gt;+ 0.4 &amp; x &lt; 0.8] &lt;- rFWE(n=sum(x &gt; 0.4 &amp; x &lt; 0.8), mu=0.4, sigma=2) y[x &gt;= 0.8] &lt;- rFWE(n=sum(x &gt;= 0.8), mu=0.5, sigma=0.5) datos &lt;- data.frame(y=y, x=x) plot(x=x, y=y) Ahora vamos a entrenar los tres modelos. library(disttree) mod1 &lt;- disttree(y ~ x, data=datos, family=NO) mod1 ## Distributional regression tree (Normal Distribution) ## ## Model formula: ## y ~ x ## ## Fitted party: ## [1] root ## | [2] x &lt;= 0.41252: n = 213 ## | mu sigma ## | 1.1230613 0.5958698 ## | [3] x &gt; 0.41252 ## | | [4] x &lt;= 0.79726: n = 186 ## | | mu sigma ## | | 1.987510 1.017759 ## | | [5] x &gt; 0.79726: n = 101 ## | | mu sigma ## | | 1.1179196 0.8208636 ## ## Number of inner nodes: 2 ## Number of terminal nodes: 3 ## Number of parameters per node: 2 ## Objective function (negative log-likelihood): 582.529 mod2 &lt;- disttree(y ~ x, data=datos, family=FWE) mod2 ## Distributional regression tree (Flexible Weibull Extension Distribution) ## ## Model formula: ## y ~ x ## ## Fitted party: ## [1] root ## | [2] x &lt;= 0.81254 ## | | [3] x &lt;= 0.41252: n = 213 ## | | mu sigma ## | | 0.710083 1.088695 ## | | [4] x &gt; 0.41252: n = 194 ## | | mu sigma ## | | 0.4154309 1.9203424 ## | [5] x &gt; 0.81254: n = 93 ## | mu sigma ## | 0.4874831 0.5628588 ## ## Number of inner nodes: 2 ## Number of terminal nodes: 3 ## Number of parameters per node: 2 ## Objective function (negative log-likelihood): 522.8889 mod3 &lt;- disttree(y ~ x, data=datos, family=WEI) mod3 ## Distributional regression tree (Weibull Distribution) ## ## Model formula: ## y ~ x ## ## Fitted party: ## [1] root ## | [2] x &lt;= 0.41252: n = 213 ## | mu sigma ## | 1.271696 2.002511 ## | [3] x &gt; 0.41252 ## | | [4] x &lt;= 0.79726: n = 186 ## | | mu sigma ## | | 2.250474 2.077362 ## | | [5] x &gt; 0.79726: n = 101 ## | | mu sigma ## | | 1.225980 1.373018 ## ## Number of inner nodes: 2 ## Number of terminal nodes: 3 ## Number of parameters per node: 2 ## Objective function (negative log-likelihood): 537.3781 En el resumen de cada modelo podemos ver al final el valor de \\(-logLik\\), el modelo más apropiado es aquel que tenga el menor valor. Al comparar los indicadores vemos que el modelo mod2 que asume FWE como distribución para \\(Y\\) es el que tiene el mejor indicador. References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
